{"cells":[{"cell_type":"markdown","metadata":{},"source":["## PlantTraits2024 simple, yet effective solution"]},{"cell_type":"markdown","metadata":{},"source":["This notebook was initially inspired by [this great notebook](https://www.kaggle.com/code/markwijkhuizen/planttraits2024-eda-training-pub), also the pickled training data is taken from there. "]},{"cell_type":"markdown","metadata":{},"source":["The solution pipeline:\n","\n","1. Clean the data - drop values that are smaller than 0.1% percentile or bigger than 98% percentile of training data;\n","2. Scale the data - using StandardScaler;\n","3. Get image embedding from DINOv2 - ([code](https://github.com/facebookresearch/dinov2/tree/main), [paper](https://arxiv.org/abs/2304.07193));\n","4. Calculate first 1000 2-degree polynomial features - using PolynomialFeatures;\n","5. Train 6 CatBoost models, one for each target - using embeddings both as numerical features and as embedding features. "]},{"cell_type":"markdown","metadata":{},"source":["The things that I've also tried but the score was smaller:\n","\n","* Use XGBoost instead of CatBoost;\n","* Tune CatBoost - use different losses, training params, use embeddings only as embeddings or only as numerical features;\n","* Train one CatBoost model instead of 6 models for each target;\n","* Use different models for embeddings - CLIP, Meta-CLIP, EVA-CLIP, BLIPv2, InternViT and other;\n","* Blend different models trained on different embeddings;\n","* Train model like in the [original notebook](https://www.kaggle.com/code/markwijkhuizen/planttraits2024-eda-training-pub) - with image backbone (Swin, ViT, ResNet) and MLP for tabular features;\n","* Add STD as targets;\n","* Use different percentiles to clean the data;"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T22:57:39.800980Z","iopub.status.busy":"2024-08-09T22:57:39.800623Z","iopub.status.idle":"2024-08-09T22:59:58.544111Z","shell.execute_reply":"2024-08-09T22:59:58.542688Z","shell.execute_reply.started":"2024-08-09T22:57:39.800950Z"},"trusted":true},"outputs":[],"source":["!pip --quiet install fastai xformers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T22:59:58.548218Z","iopub.status.busy":"2024-08-09T22:59:58.547764Z","iopub.status.idle":"2024-08-09T23:00:04.116540Z","shell.execute_reply":"2024-08-09T23:00:04.115746Z","shell.execute_reply.started":"2024-08-09T22:59:58.548172Z"},"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","from PIL import Image\n","from tqdm.notebook import tqdm\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score\n","from catboost import Pool, CatBoostRegressor\n","from torchvision import transforms\n","\n","tqdm.pandas()"]},{"cell_type":"markdown","metadata":{},"source":["## Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T23:00:04.118041Z","iopub.status.busy":"2024-08-09T23:00:04.117620Z","iopub.status.idle":"2024-08-09T23:00:04.193564Z","shell.execute_reply":"2024-08-09T23:00:04.192703Z","shell.execute_reply.started":"2024-08-09T23:00:04.118015Z"},"trusted":true},"outputs":[],"source":["class Config():\n","    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean',\n","                      'X26_mean', 'X50_mean', 'X3112_mean']\n","    # Dataset\n","    RECOMPUTE_DATAFRAMES_TRAIN = True\n","    RECOMPUTE_DATAFRAMES_TEST = True\n","    RECOMPUTE_IMAGE_EMBEDDINGS = False\n","    N_VAL_SAMPLES0 = 4096\n","    # Others\n","    SEED = 42\n","    DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","\n","\n","def seed_everything(seed: int):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","\n","\n","CONFIG = Config()\n","seed_everything(CONFIG.SEED)\n","CONFIG.DEVICE"]},{"cell_type":"markdown","metadata":{},"source":["## Load & split DataFrames"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T23:00:04.196478Z","iopub.status.busy":"2024-08-09T23:00:04.196021Z","iopub.status.idle":"2024-08-09T23:00:06.431363Z","shell.execute_reply":"2024-08-09T23:00:06.430556Z","shell.execute_reply.started":"2024-08-09T23:00:04.196443Z"},"trusted":true},"outputs":[],"source":["# load pickled dataframes from a public dataset; split to train-val\n","if CONFIG.RECOMPUTE_DATAFRAMES_TRAIN:\n","    train0 = pd.read_csv('/kaggle/input/cs-480-2024-spring/data/train.csv')\n","    train0['file_path'] = train0['id'].apply(\n","        lambda s: f'/kaggle/input/cs-480-2024-spring/data/train_images/{s}.jpeg')\n","else:\n","    train0 = pd.read_pickle(\n","        '/kaggle/input/planttraits2024-eda-training-pub-dataset/train.pkl')\n","\n","if CONFIG.RECOMPUTE_DATAFRAMES_TEST:\n","    test = pd.read_csv('/kaggle/input/cs-480-2024-spring/data/test.csv')\n","    test['file_path'] = test['id'].apply(\n","        lambda s: f'/kaggle/input/cs-480-2024-spring/data/test_images/{s}.jpeg')\n","else:\n","    test = pd.read_pickle(\n","        '/kaggle/input/planttraits2024-eda-training-pub-dataset/test.pkl')\n","CONFIG.FEATURE_COLUMNS = test.columns.values[1:-2]\n","\n","train, val = train_test_split(\n","    train0, test_size=CONFIG.N_VAL_SAMPLES0, shuffle=True, random_state=CONFIG.SEED)\n","train = train.reset_index(drop=True)\n","val = val.reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Filter outliers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T23:00:06.432760Z","iopub.status.busy":"2024-08-09T23:00:06.432471Z","iopub.status.idle":"2024-08-09T23:00:06.518896Z","shell.execute_reply":"2024-08-09T23:00:06.517971Z","shell.execute_reply.started":"2024-08-09T23:00:06.432735Z"},"trusted":true},"outputs":[],"source":["def get_mask(df, labels_describe_df):\n","    lower = []\n","    higher = []\n","    mask = np.empty(shape=df[CONFIG.TARGET_COLUMNS].shape, dtype=bool)\n","    for idx, t in enumerate(CONFIG.TARGET_COLUMNS):\n","        labels = df[t].values\n","        v_min, v_max = labels_describe_df.loc[t]['0.1%'], labels_describe_df.loc[t]['98%']\n","        mask[:, idx] = ((labels > v_min) & (labels < v_max))\n","    return mask.min(axis=1)\n","\n","\n","labels_describe_df = train[CONFIG.TARGET_COLUMNS].describe(\n","    percentiles=[0.001, 0.98]).round(3).T\n","# Masks\n","mask_train = get_mask(train, labels_describe_df)\n","mask_val = get_mask(val, labels_describe_df)\n","# Masked DataFrames\n","train_mask = train[mask_train].reset_index(drop=True)\n","val_mask = val[mask_val].reset_index(drop=True)\n","\n","for m, subset, full in zip([train_mask, val_mask], ['train', 'val'], [train, val]):\n","    print(f'===== {subset} shape: {m.shape} =====')\n","    n_masked = len(full) - len(m)\n","    perc_masked = (n_masked / len(full)) * 100\n","    print(f'{subset} \\t| # Masked Samples: {n_masked}')\n","    print(f'{subset} \\t| % Masked Samples: {perc_masked:.3f}%')"]},{"cell_type":"markdown","metadata":{},"source":["## Process features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T23:00:06.521027Z","iopub.status.busy":"2024-08-09T23:00:06.520262Z","iopub.status.idle":"2024-08-09T23:00:06.648867Z","shell.execute_reply":"2024-08-09T23:00:06.647978Z","shell.execute_reply.started":"2024-08-09T23:00:06.520990Z"},"trusted":true},"outputs":[],"source":["# Standard Scaler for Features\n","FEATURE_SCALER = StandardScaler()\n","# Fit and transform on training features\n","train_features_mask = FEATURE_SCALER.fit_transform(\n","    train_mask[CONFIG.FEATURE_COLUMNS].values.astype(np.float32))\n","# Transform val/test features using scaler fitted on train data\n","val_features_mask = FEATURE_SCALER.transform(\n","    val_mask[CONFIG.FEATURE_COLUMNS].values.astype(np.float32))\n","test_features = FEATURE_SCALER.transform(\n","    test[CONFIG.FEATURE_COLUMNS].values.astype(np.float32))\n","\n","y_train_mask = train_mask[CONFIG.TARGET_COLUMNS].values\n","y_val_mask = val_mask[CONFIG.TARGET_COLUMNS].values"]},{"cell_type":"markdown","metadata":{},"source":["## Get DINO image embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T23:00:06.650537Z","iopub.status.busy":"2024-08-09T23:00:06.650106Z","iopub.status.idle":"2024-08-09T23:00:06.657597Z","shell.execute_reply":"2024-08-09T23:00:06.656514Z","shell.execute_reply.started":"2024-08-09T23:00:06.650486Z"},"trusted":true},"outputs":[],"source":["def get_image_embeddings_dino(model, preprocess, batch_size, df):\n","    image_embeddings = []\n","    for i in tqdm(range(0, len(df), batch_size)):\n","        paths = df['file_path'][i:i + batch_size]\n","        image_tensor = torch.stack(\n","            [preprocess(Image.open(path)) for path in paths]).to(CONFIG.DEVICE)\n","        with torch.no_grad():\n","            curr_image_embeddings = model(image_tensor)\n","        image_embeddings.extend(curr_image_embeddings.cpu().numpy())\n","    return image_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T23:00:06.659177Z","iopub.status.busy":"2024-08-09T23:00:06.658897Z","iopub.status.idle":"2024-08-09T23:00:09.339730Z","shell.execute_reply":"2024-08-09T23:00:09.338818Z","shell.execute_reply.started":"2024-08-09T23:00:06.659153Z"},"trusted":true},"outputs":[],"source":["if CONFIG.RECOMPUTE_IMAGE_EMBEDDINGS:\n","    model = torch.hub.load('facebookresearch/dinov2',\n","                           'dinov2_vitg14_reg').to(CONFIG.DEVICE)\n","    model.eval()\n","    # the preprocessing differs from the original code, originally it was resize + crop\n","    # but we lose info while cropping, so here we use only resize to 224\n","    preprocess = transforms.Compose([\n","        transforms.Resize(224, interpolation=3),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4464, 0.4505, 0.3360),\n","                             (0.1834, 0.1794, 0.1779)),\n","    ])\n","\n","    batch_size = 64\n","    suffix = 'image_embs_dinov2_vitg14_reg'\n","    train_image_embeddings = get_image_embeddings_dino(\n","        model, preprocess, batch_size, train_mask)\n","    np.save(f'train_{suffix}', np.array(train_image_embeddings))\n","    val_image_embeddings = get_image_embeddings_dino(\n","        model, preprocess, batch_size, val_mask)\n","    np.save(f'val_{suffix}', np.array(val_image_embeddings))\n","    test_image_embeddings = get_image_embeddings_dino(\n","        model, preprocess, batch_size, test)\n","    np.save(f'test_{suffix}', np.array(test_image_embeddings))\n","else:\n","    suffix = 'image_embs_dinov2_vitg14_reg'\n","    train_image_embeddings = np.load(\n","        f'/kaggle/input/cs480-sping-2024-image-embeddings/train_{suffix}.npy')\n","    val_image_embeddings = np.load(\n","        f'/kaggle/input/cs480-sping-2024-image-embeddings/val_{suffix}.npy')\n","    test_image_embeddings = np.load(\n","        f'/kaggle/input/cs480-sping-2024-image-embeddings/test_{suffix}.npy')\n","    print(f'Embeddings {suffix} loaded from dataset.')"]},{"cell_type":"markdown","metadata":{},"source":["## Get final features DataFrames"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T23:00:09.341478Z","iopub.status.busy":"2024-08-09T23:00:09.341013Z","iopub.status.idle":"2024-08-09T23:00:12.304337Z","shell.execute_reply":"2024-08-09T23:00:12.303554Z","shell.execute_reply.started":"2024-08-09T23:00:09.341442Z"},"trusted":true},"outputs":[],"source":["# we can potentially use all the polynomial features but it would take an etenriny to train the models\n","first_n_poly_feats = 1000\n","train_features_mask_all = np.concatenate(\n","    (PolynomialFeatures(2).fit_transform(train_features_mask)\n","     [:, :first_n_poly_feats], train_image_embeddings), axis=1\n",")\n","val_features_mask_all = np.concatenate(\n","    (PolynomialFeatures(2).fit_transform(val_features_mask)\n","     [:, :first_n_poly_feats], val_image_embeddings), axis=1\n",")\n","test_features_all = np.concatenate(\n","    (PolynomialFeatures(2).fit_transform(test_features)[\n","     :, :first_n_poly_feats], test_image_embeddings), axis=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T23:00:12.307218Z","iopub.status.busy":"2024-08-09T23:00:12.306884Z","iopub.status.idle":"2024-08-09T23:00:12.331287Z","shell.execute_reply":"2024-08-09T23:00:12.330400Z","shell.execute_reply.started":"2024-08-09T23:00:12.307185Z"},"trusted":true},"outputs":[],"source":["train_features_mask_df = pd.DataFrame(train_features_mask_all)\n","train_features_mask_df['emb'] = list(train_image_embeddings)\n","\n","val_features_mask_df = pd.DataFrame(val_features_mask_all)\n","val_features_mask_df['emb'] = list(val_image_embeddings)\n","\n","test_features_mask_df = pd.DataFrame(test_features_all)\n","test_features_mask_df['emb'] = list(test_image_embeddings)"]},{"cell_type":"markdown","metadata":{},"source":["## Train CatBoost"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T23:00:12.332702Z","iopub.status.busy":"2024-08-09T23:00:12.332423Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["models = {}\n","scores = {}\n","for i, col in tqdm(enumerate(CONFIG.TARGET_COLUMNS), total=len(CONFIG.TARGET_COLUMNS)):\n","    y_curr = y_train_mask[:, i]\n","    y_curr_val = y_val_mask[:, i]\n","    train_pool = Pool(train_features_mask_df, y_curr,\n","                      embedding_features=['emb'])\n","    val_pool = Pool(val_features_mask_df, y_curr_val,\n","                    embedding_features=['emb'])\n","\n","    # tried to tune these parameters but without real success\n","    model = CatBoostRegressor(\n","        iterations=1900,\n","        learning_rate=0.075,\n","        loss_function='RMSE',\n","        verbose=0,\n","        random_state=CONFIG.SEED,\n","        task_type=\"GPU\",\n","        devices='0'\n","    )\n","\n","    model.fit(train_pool)\n","    models[col] = model\n","\n","    y_curr_val_pred = model.predict(val_pool)\n","\n","    r2_col = r2_score(y_curr_val, y_curr_val_pred)\n","    scores[col] = r2_col\n","    print(f'Target: {col}, R2: {r2_col:.3f}')\n","# this val score somewhat correlates with submission score bit I didn't really bother\n","print(f'Mean R2: {np.mean(list(scores.values())):.3f}')"]},{"cell_type":"markdown","metadata":{},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission = pd.DataFrame({'id': test['id']})\n","submission[CONFIG.TARGET_COLUMNS] = 0\n","submission.columns = submission.columns.str.replace('_mean', '')\n","for i, col in enumerate(CONFIG.TARGET_COLUMNS):\n","    test_pool = Pool(test_features_mask_df, embedding_features=['emb'])\n","    col_pred = models[col].predict(test_pool)\n","    submission[col.replace('_mean', '')] = col_pred\n","\n","submission.to_csv('submission_epoch1900_lr0.075_1.csv', index=False)\n","submission.head()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8915386,"sourceId":81655,"sourceType":"competition"},{"datasetId":5465878,"sourceId":9063442,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
