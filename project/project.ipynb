{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation\n",
    "\n",
    "First, let's import the necessary libraries and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the CSV files\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Define the image directories\n",
    "train_image_dir = 'data/train_images/'\n",
    "test_image_dir = 'data/test_images/'\n",
    "\n",
    "# Extract target columns and ancillary data columns\n",
    "target_columns = ['X4_mean', 'X11_mean', 'X18_mean',\n",
    "                  'X26_mean', 'X50_mean', 'X3112_mean']\n",
    "ancillary_columns = [\n",
    "    col for col in train_df.columns if col not in ['id'] + target_columns]\n",
    "\n",
    "# Extract the ids\n",
    "train_ids = train_df['id']\n",
    "test_ids = test_df['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Feature Extraction\n",
    "\n",
    "We'll use a pre-trained ResNet model to extract features from the images using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size and batch size\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transforms for preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "# Custom dataset class\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, image_dir, ids, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.ids = ids\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        img_path = os.path.join(self.image_dir, f\"{img_id}.jpeg\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = PlantDataset(train_image_dir, train_ids, transform=preprocess)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "test_dataset = PlantDataset(test_image_dir, test_ids, transform=preprocess)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "resnet_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "resnet_model.fc = nn.Identity()  # Remove the final fully connected layer\n",
    "resnet_model = resnet_model.to(device)\n",
    "\n",
    "\n",
    "# Extract features\n",
    "def extract_features(dataloader, model, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm.tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            features.append(outputs.cpu())\n",
    "    features = torch.cat(features).cpu().numpy()\n",
    "    return features\n",
    "\n",
    "\n",
    "train_features = extract_features(train_loader, resnet_model, device)\n",
    "test_features = extract_features(test_loader, resnet_model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Building\n",
    "\n",
    "Combine the image features with the ancillary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine image features with ancillary data\n",
    "train_ancillary_data = train_df[ancillary_columns].values\n",
    "test_ancillary_data = test_df[ancillary_columns].values\n",
    "\n",
    "train_combined_features = np.hstack((train_features, train_ancillary_data))\n",
    "test_combined_features = np.hstack((test_features, test_ancillary_data))\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_combined_features,\n",
    "    train_df[target_columns].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Training\n",
    "\n",
    "Train a Random Forest Regressor on the combined features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Regressor for each target trait\n",
    "models = {}\n",
    "for i, target in tqdm.tqdm(enumerate(target_columns), total=len(target_columns), desc=\"Training Models\"):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train[:, i])\n",
    "    models[target] = model\n",
    "\n",
    "    # Validate the model\n",
    "    y_pred = model.predict(X_val)\n",
    "    r2 = r2_score(y_val[:, i], y_pred)\n",
    "    print(f\"R2 score for {target}: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Prediction\n",
    "\n",
    "Use the trained models to predict the traits for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the traits for the test data\n",
    "test_predictions = {}\n",
    "for target in tqdm.tqdm(target_columns, desc=\"Predicting Traits\"):\n",
    "    test_predictions[target] = models[target].predict(test_combined_features)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'X4': test_predictions['X4_mean'],\n",
    "    'X11': test_predictions['X11_mean'],\n",
    "    'X18': test_predictions['X18_mean'],\n",
    "    'X26': test_predictions['X26_mean'],\n",
    "    'X50': test_predictions['X50_mean'],\n",
    "    'X3112': test_predictions['X3112_mean']\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
