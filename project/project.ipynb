{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation\n",
    "\n",
    "First, let's import the necessary libraries and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "# Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_file, transform=None, is_train=True):\n",
    "        self.image_dir = image_dir\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.target_columns = ['X4_mean', 'X11_mean',\n",
    "                               'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.data.iloc[idx, 0]  # Assuming the first column is 'id'\n",
    "        img_name = f\"{self.image_dir}/{img_id}.jpeg\"\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        ancillary_data = self.data.iloc[idx, 1:].drop(\n",
    "            self.target_columns, errors='ignore').values\n",
    "        if self.is_train:\n",
    "            targets = self.data.loc[idx, self.target_columns].values\n",
    "            return image, torch.tensor(ancillary_data, dtype=torch.float64), torch.tensor(targets, dtype=torch.float64), img_id\n",
    "        else:\n",
    "            return image, torch.tensor(ancillary_data, dtype=torch.float64), img_id\n",
    "\n",
    "\n",
    "# Data Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Train Dataset and DataLoader\n",
    "train_dataset = CustomDataset(image_dir='data/train_images',\n",
    "                              csv_file='data/train.csv', transform=transform, is_train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Test Dataset and DataLoader\n",
    "test_dataset = CustomDataset(image_dir='data/test_images',\n",
    "                             csv_file='data/test.csv', transform=transform, is_train=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Model Building\n",
    "\n",
    "Combine the image features with the ancillary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, num_ancillary_features, num_targets):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.vgg16 = models.vgg16(weights='DEFAULT')\n",
    "        self.vgg16.classifier = nn.Sequential(*list(self.vgg16.classifier.children())[:-3])\n",
    "        self.fc1 = nn.Linear(num_ancillary_features, 128, dtype=torch.float64)\n",
    "        self.fc2 = nn.Linear(128, 128, dtype=torch.float64)\n",
    "        self.fc3 = nn.Linear(128 + 4096, 128, dtype=torch.float64)\n",
    "        self.fc4 = nn.Linear(128, num_targets, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, image, ancillary_data):\n",
    "        x = self.vgg16(image)\n",
    "        y = torch.relu(self.fc1(ancillary_data))\n",
    "        y = torch.relu(self.fc2(y))\n",
    "        combined = torch.cat((x, y), dim=1)\n",
    "        z = torch.relu(self.fc3(combined))\n",
    "        output = self.fc4(z)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "num_ancillary_features = len(train_dataset[0][1])\n",
    "num_targets = len(train_dataset.target_columns)\n",
    "\n",
    "model = CombinedModel(num_ancillary_features, num_targets).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0., 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Training\n",
    "\n",
    "Train a Random Forest Regressor on the combined features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, ancillary_data, targets, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, ancillary_data, targets = images.to(\n",
    "            device), ancillary_data.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, ancillary_data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prediction\n",
    "\n",
    "Use the trained models to predict the traits for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Submission File\n",
    "def create_submission(model, test_loader, submission_file='submission.csv'):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, ancillary_data, ids_batch in test_loader:\n",
    "            images, ancillary_data = images.to(\n",
    "                device), ancillary_data.to(device)\n",
    "            outputs = model(images, ancillary_data)\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "            ids.extend(ids_batch)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "    with open(submission_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['id', 'X4', 'X11', 'X18', 'X26', 'X50', 'X3112'])\n",
    "        for idx, pred in zip(ids, predictions):\n",
    "            writer.writerow([idx] + list(pred))\n",
    "\n",
    "\n",
    "# Create submission\n",
    "create_submission(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
